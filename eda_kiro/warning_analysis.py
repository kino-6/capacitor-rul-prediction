#!/usr/bin/env python3
"""
è­¦å‘Šåˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
test_warnings_analysis.logãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§è­¦å‘Šã‚’åˆ†é¡ãƒ»é›†è¨ˆã™ã‚‹
"""

import re
from collections import defaultdict, Counter

def analyze_warnings():
    """è­¦å‘Šãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã—ã¦åˆ†é¡ãƒ»é›†è¨ˆã™ã‚‹"""
    
    warning_categories = defaultdict(int)
    warning_details = defaultdict(list)
    
    try:
        with open('test_warnings_analysis.log', 'r', encoding='utf-8') as f:
            content = f.read()
    except FileNotFoundError:
        print("test_warnings_analysis.logãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    lines = content.split('\n')
    
    # è­¦å‘Šãƒ‘ã‚¿ãƒ¼ãƒ³ã®å®šç¾©
    patterns = {
        'japanese_font_missing': r'UserWarning: Glyph.*missing from font\(s\) DejaVu Sans',
        'deprecation_warning': r'DeprecationWarning',
        'future_warning': r'FutureWarning',
        'runtime_warning': r'RuntimeWarning',
        'pending_deprecation': r'PendingDeprecationWarning',
        'scipy_warning': r'scipy.*Warning',
        'statsmodels_warning': r'statsmodels.*Warning',
        'pandas_warning': r'pandas.*Warning',
        'japanize_matplotlib_warning': r'japanize.*Warning',
        'setuptools_warning': r'setuptools.*Warning',
        'user_warning': r'UserWarning',
    }
    
    # å„è¡Œã‚’åˆ†æ
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆä¸è¶³è­¦å‘Šï¼ˆæœ€ã‚‚å¤šã„ï¼‰
        if re.search(patterns['japanese_font_missing'], line):
            warning_categories['æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆä¸è¶³ (matplotlib)'] += 1
            # å…·ä½“çš„ãªæ–‡å­—ã‚’æŠ½å‡º
            glyph_match = re.search(r'Glyph (\d+) \(\\N\{([^}]+)\}\)', line)
            if glyph_match:
                char_code, char_name = glyph_match.groups()
                warning_details['æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆä¸è¶³'].append(f"{char_name} (U+{int(char_code):04X})")
        
        # ãã®ä»–ã®è­¦å‘Šã‚¿ã‚¤ãƒ—
        elif 'DeprecationWarning' in line:
            warning_categories['éæ¨å¥¨è­¦å‘Š (DeprecationWarning)'] += 1
            if 'japanize' in line.lower():
                warning_details['éæ¨å¥¨è­¦å‘Š'].append('japanize-matplotlibé–¢é€£')
            elif 'setuptools' in line.lower():
                warning_details['éæ¨å¥¨è­¦å‘Š'].append('setuptoolsé–¢é€£')
            elif 'pandas' in line.lower():
                warning_details['éæ¨å¥¨è­¦å‘Š'].append('pandasé–¢é€£')
            else:
                warning_details['éæ¨å¥¨è­¦å‘Š'].append('ãã®ä»–')
                
        elif 'FutureWarning' in line:
            warning_categories['å°†æ¥è­¦å‘Š (FutureWarning)'] += 1
            warning_details['å°†æ¥è­¦å‘Š'].append(line[:100] + '...' if len(line) > 100 else line)
            
        elif 'RuntimeWarning' in line:
            warning_categories['å®Ÿè¡Œæ™‚è­¦å‘Š (RuntimeWarning)'] += 1
            warning_details['å®Ÿè¡Œæ™‚è­¦å‘Š'].append(line[:100] + '...' if len(line) > 100 else line)
            
        elif 'PendingDeprecationWarning' in line:
            warning_categories['ä¿ç•™éæ¨å¥¨è­¦å‘Š'] += 1
            
        elif 'UserWarning' in line and 'scipy' in line.lower():
            warning_categories['scipyè­¦å‘Š'] += 1
            warning_details['scipyè­¦å‘Š'].append('MATLABå½¢å¼ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿é–¢é€£')
            
        elif 'UserWarning' in line and 'statsmodels' in line.lower():
            warning_categories['statsmodelsè­¦å‘Š'] += 1
            warning_details['statsmodelsè­¦å‘Š'].append('çµ±è¨ˆè¨ˆç®—é–¢é€£')
    
    # çµæœã®å‡ºåŠ›
    print("=" * 60)
    print("NASA PCOE EDA ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆè­¦å‘Šåˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
    print("=" * 60)
    print()
    
    print("ğŸ“Š è­¦å‘Šã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ:")
    print("-" * 40)
    total_warnings = sum(warning_categories.values())
    
    for category, count in sorted(warning_categories.items(), key=lambda x: x[1], reverse=True):
        percentage = (count / total_warnings * 100) if total_warnings > 0 else 0
        print(f"{category}: {count:,} ä»¶ ({percentage:.1f}%)")
    
    print(f"\nåˆè¨ˆè­¦å‘Šæ•°: {total_warnings:,} ä»¶")
    print()
    
    # è©³ç´°åˆ†æ
    print("ğŸ” è©³ç´°åˆ†æ:")
    print("-" * 40)
    
    # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆä¸è¶³ã®è©³ç´°
    if 'æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆä¸è¶³' in warning_details:
        font_chars = Counter(warning_details['æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆä¸è¶³'])
        print(f"\nğŸ“ æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆä¸è¶³ã®è©³ç´° (ä¸Šä½10æ–‡å­—):")
        for char, count in font_chars.most_common(10):
            print(f"  {char}: {count} å›")
    
    # éæ¨å¥¨è­¦å‘Šã®è©³ç´°
    if 'éæ¨å¥¨è­¦å‘Š' in warning_details:
        dep_sources = Counter(warning_details['éæ¨å¥¨è­¦å‘Š'])
        print(f"\nâš ï¸  éæ¨å¥¨è­¦å‘Šã®å†…è¨³:")
        for source, count in dep_sources.items():
            print(f"  {source}: {count} ä»¶")
    
    print()
    print("ğŸ’¡ æ¨å¥¨å¯¾å¿œ:")
    print("-" * 40)
    print("1. æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆä¸è¶³è­¦å‘Š:")
    print("   - æ©Ÿèƒ½ã«å½±éŸ¿ãªã—ï¼ˆè¡¨ç¤ºã®ã¿ã®å•é¡Œï¼‰")
    print("   - æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’ã‚·ã‚¹ãƒ†ãƒ ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã“ã¨ã§è§£æ±ºå¯èƒ½")
    print("   - æœ¬ç•ªç’°å¢ƒã§ã¯è‹±èªãƒ©ãƒ™ãƒ«ã®ä½¿ç”¨ã‚’æ¤œè¨")
    print()
    print("2. éæ¨å¥¨è­¦å‘Š:")
    print("   - ä¾å­˜é–¢ä¿‚ã®æ›´æ–°æ™‚ã«å¯¾å¿œã‚’æ¤œè¨")
    print("   - ç¾åœ¨ã¯æ©Ÿèƒ½ã«å½±éŸ¿ãªã—")
    print()
    print("3. ãã®ä»–ã®è­¦å‘Š:")
    print("   - çµ±è¨ˆè¨ˆç®—ã‚„ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿é–¢é€£ã®æƒ…å ±è­¦å‘Š")
    print("   - æ©Ÿèƒ½ã«å½±éŸ¿ãªã—")

if __name__ == "__main__":
    analyze_warnings()