# Phase 2 結果分析と改善提案

## 📅 作成日: 2026-01-17

## 🔍 現状分析

### 1. Primary Model（異常検知）の問題

#### 観察された現象
- **Train/Val/Test全てで100%の精度** 
- 完璧すぎる性能 = 明らかな異常

#### 根本原因の特定

**データリーケージ（Data Leakage）が発生している**

```
ラベリング戦略:
- サイクル1-100（前半50%）→ Normal (is_abnormal=0)
- サイクル101-200（後半50%）→ Abnormal (is_abnormal=1)

特徴量:
- cycle_number: サイクル番号そのもの
- cycle_normalized: サイクル番号を正規化したもの

問題:
モデルは「cycle_number > 100 なら Abnormal」という
単純なルールを学習しているだけ
→ 実際の劣化パターンを学習していない
```

#### 証拠

1. **特徴量重要度**（Phase 2レポートより）:
   - cycle_number: 18.88%
   - cycle_normalized: 15.25%
   - **合計34%がサイクル情報に依存**

2. **Train/Val/Test全てで完璧な性能**:
   - 真の汎化ではなく、サイクル番号を暗記しているだけ

### 2. Secondary Model（RUL予測）の問題

#### 観察された現象

| RUL範囲 | MAE | 性能 |
|---------|-----|------|
| 0-50 | 26.04 | ⚠️ 極めて悪い |
| 50-100 | 0.51 | ✅ 優秀 |
| 100-150 | 0.08 | ✅ 優秀 |
| 150-200 | 0.54 | ✅ 優秀 |

**Train MAE: 0.07 → Test MAE: 6.79（100倍以上の差）**

#### 根本原因

**1. 訓練データの範囲制限**

```
訓練データ: C1-C5のサイクル1-150
→ RUL範囲: 50-199（200-1=199, 200-150=50）

テストデータ: C7-C8のサイクル1-200
→ RUL範囲: 0-199（200-1=199, 200-200=0）

問題:
- RUL < 50のデータが訓練セットに存在しない
- モデルは外挿（extrapolation）できない
- 最小RUL値≈50を学習してしまった
```

**2. サイクル番号への過度な依存**

特徴量重要度（Phase 2レポートより）:
- cycle_normalized: 45.32%
- cycle_number: 45.03%
- **合計90%以上がサイクル情報に依存**

→ 実際の劣化指標（VO, VL）をほとんど使っていない

**3. Overfitting**

- Train MAE: 0.07（ほぼ完璧）
- Test MAE: 6.79（100倍悪化）
- 訓練データを暗記しているだけで、汎化していない

---

## 💡 改善提案

### 優先度1: データリーケージの解消（最重要）

#### 問題
cycle_number/cycle_normalizedがラベルと直接相関している

#### 解決策

**A. サイクル関連特徴量の除外**

```python
# 除外すべき特徴量
features_to_remove = [
    'cycle_number',
    'cycle_normalized'
]

# 残すべき特徴量
features_to_keep = [
    # VL（入力電圧）関連
    'vl_mean', 'vl_std', 'vl_cv', 'vl_max', 'vl_min', 
    'vl_range', 'vl_median', 'vl_q25', 'vl_q75', 'vl_iqr',
    
    # VO（出力電圧）関連
    'vo_mean', 'vo_std', 'vo_cv', 'vo_max', 'vo_min',
    'vo_range', 'vo_median', 'vo_q25', 'vo_q75', 'vo_iqr',
    
    # 劣化指標
    'voltage_ratio_mean', 'voltage_ratio_std', 'voltage_ratio_cv',
    'voltage_ratio_max', 'voltage_ratio_min', 'voltage_ratio_range'
]
```

**期待される効果**:
- モデルが実際の電圧パターンから劣化を学習
- 真の汎化性能が測定可能になる
- Primary Modelの精度は下がるが、それが正しい姿

---

### 優先度2: ラベリング戦略の見直し

#### 現在の問題
サイクル位置ベースのラベリング（前半50%=Normal, 後半50%=Abnormal）は単純すぎる

#### 改善案

**A. 閾値ベースのラベリング**

```python
# 例: voltage_ratio（VO/VL）の変化に基づく
threshold = 0.95  # 初期値の95%以下になったら異常

def label_by_degradation(cycle_data):
    initial_ratio = cycle_data['voltage_ratio_mean'].iloc[0]
    threshold_value = initial_ratio * threshold
    
    is_abnormal = cycle_data['voltage_ratio_mean'] < threshold_value
    return is_abnormal
```

**B. 専門家知識の活用**

- 実際のコンデンサの劣化メカニズムに基づく
- 容量低下、ESR増加などの物理的指標を使用

---

### 優先度3: 訓練データの拡張

#### 問題
- RUL < 50のデータが訓練セットにない
- データ量が少ない（750サンプル）

#### 解決策

**A. データ分割戦略の変更**

```python
# 現在
Train: C1-C5のサイクル1-150（RUL: 50-199）
Val: C6のサイクル1-150（RUL: 50-199）
Test: C7-C8のサイクル1-200（RUL: 0-199）

# 改善案
Train: C1-C5のサイクル1-200（RUL: 0-199）← 全サイクル使用
Val: C6のサイクル1-200（RUL: 0-199）
Test: C7-C8のサイクル1-200（RUL: 0-199）
```

**期待される効果**:
- 訓練データ: 750 → 1000サンプル（+33%）
- RUL全範囲をカバー
- 寿命末期の予測が可能に

**B. ES10/ES14データの追加**

```python
# ES10: 8コンデンサ × 400サイクル = 3200サンプル
# ES14: 8コンデンサ × 400サイクル = 3200サンプル
# ES12: 8コンデンサ × 200サイクル = 1600サンプル

# 合計: 8000サンプル（現在の10倍以上）
```

---

### 優先度4: 特徴量エンジニアリング

#### 問題
劣化を表す特徴量が不足している

#### 改善案

**A. 履歴特徴量の追加**

```python
# 過去Nサイクルの統計
- voltage_ratio_mean_last_5: 過去5サイクルの平均
- voltage_ratio_std_last_5: 過去5サイクルの標準偏差
- voltage_ratio_trend_last_10: 過去10サイクルのトレンド（線形回帰の傾き）

# 劣化率
- degradation_rate: (現在の値 - 初期値) / 初期値
- degradation_velocity: 劣化率の変化速度
```

**B. ドメイン知識に基づく特徴量**

```python
# コンデンサの物理的特性
- capacitance_estimate: 推定容量
- esr_estimate: 推定ESR（等価直列抵抗）
- power_loss: 電力損失の推定
```

---

### 優先度5: モデルアーキテクチャの改善

#### 現在の問題
Random Forestは時系列の依存関係を考慮しない

#### 改善案

**A. 時系列モデルの導入**

```python
# LSTM/GRUによる時系列モデリング
- 過去Nサイクルの特徴量系列を入力
- 時間的な劣化パターンを学習
- より正確なRUL予測が可能
```

**B. アンサンブル手法**

```python
# 複数モデルの組み合わせ
- Random Forest（ベースライン）
- XGBoost（勾配ブースティング）
- LSTM（時系列）
→ 投票またはスタッキングで統合
```

---

## 🎯 推奨される実装順序

### ステップ1: データリーケージの解消（即実施）

1. cycle_number, cycle_normalizedを特徴量から除外
2. モデルを再訓練
3. 性能を再評価

**期待される結果**:
- Primary Model: 精度が下がる（70-80%程度）← これが正常
- Secondary Model: 大きな変化なし（サイクル情報への依存度が高いため）

### ステップ2: データ分割の変更（即実施）

1. 訓練データを全サイクル（1-200）に拡張
2. モデルを再訓練
3. RUL < 50の性能を確認

**期待される結果**:
- Secondary Model: RUL 0-50のMAEが大幅改善（26.04 → 5以下）

### ステップ3: ラベリング戦略の見直し（中期）

1. 閾値ベースのラベリングを実装
2. 専門家知識を組み込む
3. モデルを再訓練

**期待される結果**:
- Primary Model: より実用的な異常検知
- 実際の劣化パターンを学習

### ステップ4: ES10/ES14データの追加（中期）

1. ES10/ES14から特徴量を抽出
2. 統合データセットで訓練
3. クロスデータセット検証

**期待される結果**:
- データ量10倍増加
- 汎化性能の大幅向上
- ドメインシフトへの対応

### ステップ5: 高度な特徴量とモデル（長期）

1. 履歴特徴量の追加
2. LSTMなどの時系列モデル
3. アンサンブル手法

**期待される結果**:
- 最先端の予測精度
- 実用レベルのシステム

---

## 📊 期待される改善効果

### Before（現在）

| モデル | 指標 | 値 | 問題 |
|--------|------|-----|------|
| Primary | F1-Score | 1.0000 | データリーケージ |
| Secondary | MAE (RUL 0-50) | 26.04 | 外挿不可 |
| Secondary | MAE (RUL 50+) | 0.38 | Overfitting |

### After（ステップ1-2実施後）

| モデル | 指標 | 予想値 | 改善 |
|--------|------|--------|------|
| Primary | F1-Score | 0.75-0.85 | 真の性能 |
| Secondary | MAE (RUL 0-50) | 3-5 | 大幅改善 |
| Secondary | MAE (RUL 50+) | 1-2 | 安定化 |

### After（ステップ3-4実施後）

| モデル | 指標 | 予想値 | 改善 |
|--------|------|--------|------|
| Primary | F1-Score | 0.85-0.90 | 実用レベル |
| Secondary | MAE (全範囲) | 2-3 | 実用レベル |
| Secondary | R² | 0.95+ | 高精度 |

---

## 🚨 重要な気づき

### 現在のモデルは「学習できていない」のではなく「間違ったものを学習している」

1. **Primary Model**: サイクル番号を暗記（劣化パターンは学習していない）
2. **Secondary Model**: サイクル番号からRULを計算（劣化指標は使っていない）

### これは「データの見方が間違っている」問題

- ラベリング戦略が単純すぎる
- 特徴量にリーケージがある
- データ分割が不適切

### 解決策は明確

1. **即座に実施**: cycle_number除外 + データ分割変更
2. **中期的に実施**: ラベリング改善 + ES10/ES14追加
3. **長期的に実施**: 高度な特徴量 + 時系列モデル

---

## 📝 次のアクション

### 推奨: ステップ1-2を即座に実施

```bash
# 1. 特徴量からcycle_number/cycle_normalizedを除外
# 2. データ分割を変更（全サイクル使用）
# 3. モデルを再訓練
# 4. 性能を再評価
```

**所要時間**: 1-2時間
**期待される効果**: 大幅な改善

### その後: Phase 2.5の残りタスクを実施

- Task 6.4-6.5: ES10/ES14データ整備
- Task 6.6: 外部検証

---

**作成者**: Kiro AI Agent  
**ステータス**: Phase 2 結果分析完了  
**推奨アクション**: ステップ1-2の即時実施
