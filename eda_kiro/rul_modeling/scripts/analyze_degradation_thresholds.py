"""
Analyze degradation patterns and identify failure threshold candidates.

This script performs detailed analysis of response features to:
1. Visualize degradation patterns over time
2. Identify threshold candidates for failure detection
3. Define degradation stages (Normal, Degrading, Severe, Critical)
4. Analyze feature distributions across stages
"""

import sys
from pathlib import Path
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

# Paths
BASE_DIR = Path(__file__).parent.parent
FEATURES_PATH = BASE_DIR / "output" / "features_v3" / "es12_response_features.csv"
OUTPUT_DIR = BASE_DIR / "output" / "features_v3"

# Set style
sns.set_style("whitegrid")
plt.rcParams['font.size'] = 10


def analyze_threshold_candidates(df):
    """Analyze threshold candidates for failure detection."""
    print("\n" + "="*80)
    print("THRESHOLD CANDIDATE ANALYSIS")
    print("="*80)
    
    # Define threshold candidates
    thresholds = {
        'response_efficiency': [50, 10, 5, 2, 1],
        'efficiency_degradation_rate': [0.5, 0.8, 0.9, 0.95, 0.98],
        'waveform_correlation': [0.90, 0.95, 0.98, 0.99, 0.995]
    }
    
    results = []
    
    for feature, threshold_list in thresholds.items():
        print(f"\n{feature}:")
        print("-" * 80)
        
        for threshold in threshold_list:
            # Count samples below/above threshold
            if feature == 'response_efficiency':
                # Lower is worse
                failing = df[df[feature] < threshold]
                condition = f"< {threshold}"
            elif feature == 'efficiency_degradation_rate':
                # Higher is worse (more degraded)
                # Skip NaN values
                valid_df = df[df[feature].notna()]
                failing = valid_df[valid_df[feature] > threshold]
                condition = f"> {threshold}"
            else:  # waveform_correlation
                # Higher is worse (more simplified)
                failing = df[df[feature] > threshold]
                condition = f"> {threshold}"
            
            failing_pct = len(failing) / len(df) * 100
            
            # Find first cycle where each capacitor crosses threshold
            first_cycles = []
            for cap_id in df['capacitor_id'].unique():
                cap_data = df[df['capacitor_id'] == cap_id].sort_values('cycle')
                
                if feature == 'response_efficiency':
                    crossing = cap_data[cap_data[feature] < threshold]
                elif feature == 'efficiency_degradation_rate':
                    cap_data_valid = cap_data[cap_data[feature].notna()]
                    crossing = cap_data_valid[cap_data_valid[feature] > threshold]
                else:
                    crossing = cap_data[cap_data[feature] > threshold]
                
                if len(crossing) > 0:
                    first_cycles.append(crossing.iloc[0]['cycle'])
            
            avg_first_cycle = np.mean(first_cycles) if first_cycles else None
            
            print(f"  {condition}: {len(failing)} samples ({failing_pct:.1f}%)")
            if avg_first_cycle:
                print(f"    Average first detection: Cycle {avg_first_cycle:.1f}")
            
            results.append({
                'feature': feature,
                'threshold': threshold,
                'condition': condition,
                'failing_samples': len(failing),
                'failing_pct': failing_pct,
                'avg_first_cycle': avg_first_cycle
            })
    
    return pd.DataFrame(results)


def define_degradation_stages(df):
    """Define degradation stages based on response efficiency."""
    print("\n" + "="*80)
    print("DEGRADATION STAGE DEFINITION")
    print("="*80)
    
    # Define stages based on response efficiency
    def classify_stage(eff):
        if eff > 50:
            return 'Normal'
        elif eff > 10:
            return 'Degrading'
        elif eff > 1:
            return 'Severe'
        else:
            return 'Critical'
    
    df['degradation_stage'] = df['response_efficiency'].apply(classify_stage)
    
    # Count samples per stage
    stage_counts = df['degradation_stage'].value_counts()
    print("\nSample Distribution by Stage:")
    print("-" * 80)
    for stage in ['Normal', 'Degrading', 'Severe', 'Critical']:
        if stage in stage_counts:
            count = stage_counts[stage]
            pct = count / len(df) * 100
            print(f"  {stage:12s}: {count:4d} samples ({pct:5.1f}%)")
    
    # Analyze feature ranges per stage
    print("\nFeature Ranges by Stage:")
    print("-" * 80)
    
    key_features = [
        'response_efficiency',
        'voltage_ratio',
        'waveform_correlation',
        'efficiency_degradation_rate'
    ]
    
    for stage in ['Normal', 'Degrading', 'Severe', 'Critical']:
        stage_data = df[df['degradation_stage'] == stage]
        if len(stage_data) == 0:
            continue
        
        print(f"\n{stage}:")
        for feat in key_features:
            if feat == 'efficiency_degradation_rate':
                # Skip NaN values
                valid_data = stage_data[stage_data[feat].notna()]
                if len(valid_data) == 0:
                    continue
                mean_val = valid_data[feat].mean()
                std_val = valid_data[feat].std()
            else:
                mean_val = stage_data[feat].mean()
                std_val = stage_data[feat].std()
            
            print(f"  {feat:30s}: {mean_val:8.2f} Â± {std_val:8.2f}")
    
    return df


def visualize_degradation_patterns(df):
    """Create comprehensive degradation pattern visualizations."""
    print("\n" + "="*80)
    print("CREATING DEGRADATION PATTERN VISUALIZATIONS")
    print("="*80)
    
    # Create figure with multiple subplots
    fig = plt.figure(figsize=(20, 12))
    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)
    
    capacitors = sorted(df['capacitor_id'].unique())
    colors = plt.cm.tab10(np.linspace(0, 1, len(capacitors)))
    
    # 1. Response Efficiency with threshold lines
    ax1 = fig.add_subplot(gs[0, :])
    for i, cap_id in enumerate(capacitors):
        cap_data = df[df['capacitor_id'] == cap_id]
        ax1.plot(cap_data['cycle'], cap_data['response_efficiency'], 
                label=cap_id, color=colors[i], alpha=0.7, linewidth=1.5)
    
    # Add threshold lines
    ax1.axhline(y=50, color='orange', linestyle='--', linewidth=2, label='Threshold: 50% (Normal/Degrading)')
    ax1.axhline(y=10, color='red', linestyle='--', linewidth=2, label='Threshold: 10% (Degrading/Severe)')
    ax1.axhline(y=1, color='darkred', linestyle='--', linewidth=2, label='Threshold: 1% (Severe/Critical)')
    
    ax1.set_xlabel('Cycle', fontsize=12, fontweight='bold')
    ax1.set_ylabel('Response Efficiency', fontsize=12, fontweight='bold')
    ax1.set_title('Response Efficiency Over Time with Degradation Thresholds', 
                  fontsize=14, fontweight='bold')
    ax1.legend(loc='upper right', fontsize=9, ncol=2)
    ax1.grid(True, alpha=0.3)
    ax1.set_ylim(bottom=0)
    
    # 2. Efficiency Degradation Rate
    ax2 = fig.add_subplot(gs[1, 0])
    for i, cap_id in enumerate(capacitors):
        cap_data = df[df['capacitor_id'] == cap_id]
        cap_data_valid = cap_data[cap_data['efficiency_degradation_rate'].notna()]
        ax2.plot(cap_data_valid['cycle'], cap_data_valid['efficiency_degradation_rate'], 
                label=cap_id, color=colors[i], alpha=0.7, linewidth=1.5)
    
    ax2.axhline(y=0.5, color='orange', linestyle='--', linewidth=1.5, alpha=0.7)
    ax2.axhline(y=0.9, color='red', linestyle='--', linewidth=1.5, alpha=0.7)
    ax2.set_xlabel('Cycle', fontsize=11, fontweight='bold')
    ax2.set_ylabel('Efficiency Degradation Rate', fontsize=11, fontweight='bold')
    ax2.set_title('Efficiency Degradation Rate', fontsize=12, fontweight='bold')
    ax2.legend(loc='upper left', fontsize=8)
    ax2.grid(True, alpha=0.3)
    
    # 3. Waveform Correlation
    ax3 = fig.add_subplot(gs[1, 1])
    for i, cap_id in enumerate(capacitors):
        cap_data = df[df['capacitor_id'] == cap_id]
        ax3.plot(cap_data['cycle'], cap_data['waveform_correlation'], 
                label=cap_id, color=colors[i], alpha=0.7, linewidth=1.5)
    
    ax3.axhline(y=0.95, color='orange', linestyle='--', linewidth=1.5, alpha=0.7)
    ax3.axhline(y=0.99, color='red', linestyle='--', linewidth=1.5, alpha=0.7)
    ax3.set_xlabel('Cycle', fontsize=11, fontweight='bold')
    ax3.set_ylabel('Waveform Correlation', fontsize=11, fontweight='bold')
    ax3.set_title('Waveform Correlation (Simplification)', fontsize=12, fontweight='bold')
    ax3.legend(loc='lower right', fontsize=8)
    ax3.grid(True, alpha=0.3)
    
    # 4. VO Variability
    ax4 = fig.add_subplot(gs[1, 2])
    for i, cap_id in enumerate(capacitors):
        cap_data = df[df['capacitor_id'] == cap_id]
        ax4.plot(cap_data['cycle'], cap_data['vo_variability'], 
                label=cap_id, color=colors[i], alpha=0.7, linewidth=1.5)
    
    ax4.set_xlabel('Cycle', fontsize=11, fontweight='bold')
    ax4.set_ylabel('VO Variability', fontsize=11, fontweight='bold')
    ax4.set_title('VO Variability Over Time', fontsize=12, fontweight='bold')
    ax4.legend(loc='upper right', fontsize=8)
    ax4.grid(True, alpha=0.3)
    
    # 5. Distribution by Stage - Response Efficiency
    ax5 = fig.add_subplot(gs[2, 0])
    stage_order = ['Normal', 'Degrading', 'Severe', 'Critical']
    stage_colors = {'Normal': 'green', 'Degrading': 'orange', 'Severe': 'red', 'Critical': 'darkred'}
    
    for stage in stage_order:
        stage_data = df[df['degradation_stage'] == stage]
        if len(stage_data) > 0:
            ax5.hist(stage_data['response_efficiency'], bins=30, alpha=0.6, 
                    label=f"{stage} (n={len(stage_data)})", color=stage_colors[stage])
    
    ax5.set_xlabel('Response Efficiency', fontsize=11, fontweight='bold')
    ax5.set_ylabel('Frequency', fontsize=11, fontweight='bold')
    ax5.set_title('Response Efficiency Distribution by Stage', fontsize=12, fontweight='bold')
    ax5.legend(loc='upper right', fontsize=9)
    ax5.grid(True, alpha=0.3, axis='y')
    ax5.set_xlim(left=0)
    
    # 6. Box plot - Response Efficiency by Stage
    ax6 = fig.add_subplot(gs[2, 1])
    stage_data_list = [df[df['degradation_stage'] == stage]['response_efficiency'].values 
                       for stage in stage_order if len(df[df['degradation_stage'] == stage]) > 0]
    stage_labels = [stage for stage in stage_order if len(df[df['degradation_stage'] == stage]) > 0]
    
    bp = ax6.boxplot(stage_data_list, labels=stage_labels, patch_artist=True)
    for patch, stage in zip(bp['boxes'], stage_labels):
        patch.set_facecolor(stage_colors[stage])
        patch.set_alpha(0.6)
    
    ax6.set_ylabel('Response Efficiency', fontsize=11, fontweight='bold')
    ax6.set_title('Response Efficiency by Degradation Stage', fontsize=12, fontweight='bold')
    ax6.grid(True, alpha=0.3, axis='y')
    ax6.set_yscale('log')
    
    # 7. Cycle distribution by stage
    ax7 = fig.add_subplot(gs[2, 2])
    for stage in stage_order:
        stage_data = df[df['degradation_stage'] == stage]
        if len(stage_data) > 0:
            ax7.hist(stage_data['cycle'], bins=20, alpha=0.6, 
                    label=f"{stage} (n={len(stage_data)})", color=stage_colors[stage])
    
    ax7.set_xlabel('Cycle', fontsize=11, fontweight='bold')
    ax7.set_ylabel('Frequency', fontsize=11, fontweight='bold')
    ax7.set_title('Cycle Distribution by Degradation Stage', fontsize=12, fontweight='bold')
    ax7.legend(loc='upper right', fontsize=9)
    ax7.grid(True, alpha=0.3, axis='y')
    
    plt.suptitle('Degradation Pattern Analysis with Threshold Identification', 
                 fontsize=16, fontweight='bold', y=0.995)
    
    # Save figure
    output_path = OUTPUT_DIR / "degradation_patterns_detailed.png"
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"\nâœ“ Saved: {output_path}")
    plt.close()


def create_threshold_analysis_report(df, threshold_results):
    """Create markdown report with threshold analysis."""
    print("\n" + "="*80)
    print("CREATING THRESHOLD ANALYSIS REPORT")
    print("="*80)
    
    report_path = OUTPUT_DIR / "degradation_stages_definition.md"
    
    with open(report_path, 'w') as f:
        f.write("# åŠ£åŒ–ã‚¹ãƒ†ãƒ¼ã‚¸å®šç¾©ã¨é–¾å€¤åˆ†æãƒ¬ãƒãƒ¼ãƒˆ\n\n")
        f.write("**ä½œæˆæ—¥**: 2026-01-17  \n")
        f.write("**ã‚¿ã‚¹ã‚¯**: Phase 1 Task 1.4 - åŠ£åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è©³ç´°å¯è¦–åŒ–ã¨é–¾å€¤æ¢ç´¢  \n\n")
        f.write("---\n\n")
        
        f.write("## ğŸ“‹ æ¦‚è¦\n\n")
        f.write("å¿œç­”æ€§ç‰¹å¾´é‡ã®æ™‚ç³»åˆ—åˆ†æã«åŸºã¥ãã€æ•…éšœå…†å€™ã‚’ç¤ºã™é–¾å€¤å€™è£œã‚’ç‰¹å®šã—ã€\n")
        f.write("åŠ£åŒ–ã‚¹ãƒ†ãƒ¼ã‚¸ï¼ˆNormal, Degrading, Severe, Criticalï¼‰ã‚’å®šç¾©ã—ã¾ã—ãŸã€‚\n\n")
        f.write("---\n\n")
        
        f.write("## ğŸ¯ åŠ£åŒ–ã‚¹ãƒ†ãƒ¼ã‚¸ã®å®šç¾©\n\n")
        f.write("Response Efficiencyã‚’åŸºæº–ã¨ã—ã¦ã€4ã¤ã®åŠ£åŒ–ã‚¹ãƒ†ãƒ¼ã‚¸ã‚’å®šç¾©:\n\n")
        f.write("| ã‚¹ãƒ†ãƒ¼ã‚¸ | Response Efficiency | èª¬æ˜ |\n")
        f.write("|---------|---------------------|------|\n")
        f.write("| **Normal** | > 50% | æ­£å¸¸å‹•ä½œç¯„å›²ã€‚VL-VOå¿œç­”æ€§ãŒè‰¯å¥½ |\n")
        f.write("| **Degrading** | 10% - 50% | åŠ£åŒ–é€²è¡Œä¸­ã€‚å¿œç­”æ€§ãŒä½ä¸‹ã—å§‹ã‚ã‚‹ |\n")
        f.write("| **Severe** | 1% - 10% | æ·±åˆ»ãªåŠ£åŒ–ã€‚å¿œç­”æ€§ãŒå¤§å¹…ã«ä½ä¸‹ |\n")
        f.write("| **Critical** | < 1% | è‡¨ç•ŒçŠ¶æ…‹ã€‚ã»ã¼å¿œç­”ãªã— |\n\n")
        
        # Sample distribution
        stage_counts = df['degradation_stage'].value_counts()
        f.write("### ã‚µãƒ³ãƒ—ãƒ«åˆ†å¸ƒ\n\n")
        f.write("```\n")
        for stage in ['Normal', 'Degrading', 'Severe', 'Critical']:
            if stage in stage_counts:
                count = stage_counts[stage]
                pct = count / len(df) * 100
                f.write(f"{stage:12s}: {count:4d} samples ({pct:5.1f}%)\n")
        f.write("```\n\n")
        
        f.write("---\n\n")
        f.write("## ğŸ“Š é–¾å€¤å€™è£œã®åˆ†æ\n\n")
        
        # Response Efficiency thresholds
        f.write("### 1. Response Efficiency é–¾å€¤\n\n")
        f.write("| é–¾å€¤ | æ¡ä»¶ | è©²å½“ã‚µãƒ³ãƒ—ãƒ«æ•° | å‰²åˆ | å¹³å‡æ¤œå‡ºã‚µã‚¤ã‚¯ãƒ« |\n")
        f.write("|------|------|---------------|------|----------------|\n")
        
        eff_results = threshold_results[threshold_results['feature'] == 'response_efficiency']
        for _, row in eff_results.iterrows():
            avg_cycle = f"{row['avg_first_cycle']:.1f}" if pd.notna(row['avg_first_cycle']) else "N/A"
            f.write(f"| {row['threshold']}% | {row['condition']} | {row['failing_samples']} | "
                   f"{row['failing_pct']:.1f}% | Cycle {avg_cycle} |\n")
        
        f.write("\n**æ¨å¥¨é–¾å€¤**: 50% (Normal/Degradingå¢ƒç•Œ), 10% (Degrading/Severeå¢ƒç•Œ), 1% (Severe/Criticalå¢ƒç•Œ)\n\n")
        
        # Efficiency Degradation Rate thresholds
        f.write("### 2. Efficiency Degradation Rate é–¾å€¤\n\n")
        f.write("| é–¾å€¤ | æ¡ä»¶ | è©²å½“ã‚µãƒ³ãƒ—ãƒ«æ•° | å‰²åˆ | å¹³å‡æ¤œå‡ºã‚µã‚¤ã‚¯ãƒ« |\n")
        f.write("|------|------|---------------|------|----------------|\n")
        
        deg_results = threshold_results[threshold_results['feature'] == 'efficiency_degradation_rate']
        for _, row in deg_results.iterrows():
            avg_cycle = f"{row['avg_first_cycle']:.1f}" if pd.notna(row['avg_first_cycle']) else "N/A"
            f.write(f"| {row['threshold']} | {row['condition']} | {row['failing_samples']} | "
                   f"{row['failing_pct']:.1f}% | Cycle {avg_cycle} |\n")
        
        f.write("\n**æ¨å¥¨é–¾å€¤**: 0.5 (50%åŠ£åŒ–), 0.9 (90%åŠ£åŒ–)\n\n")
        
        # Waveform Correlation thresholds
        f.write("### 3. Waveform Correlation é–¾å€¤\n\n")
        f.write("| é–¾å€¤ | æ¡ä»¶ | è©²å½“ã‚µãƒ³ãƒ—ãƒ«æ•° | å‰²åˆ | å¹³å‡æ¤œå‡ºã‚µã‚¤ã‚¯ãƒ« |\n")
        f.write("|------|------|---------------|------|----------------|\n")
        
        corr_results = threshold_results[threshold_results['feature'] == 'waveform_correlation']
        for _, row in corr_results.iterrows():
            avg_cycle = f"{row['avg_first_cycle']:.1f}" if pd.notna(row['avg_first_cycle']) else "N/A"
            f.write(f"| {row['threshold']} | {row['condition']} | {row['failing_samples']} | "
                   f"{row['failing_pct']:.1f}% | Cycle {avg_cycle} |\n")
        
        f.write("\n**æ¨å¥¨é–¾å€¤**: 0.95 (æ³¢å½¢å˜ç´”åŒ–é–‹å§‹), 0.99 (æ·±åˆ»ãªå˜ç´”åŒ–)\n\n")
        
        f.write("---\n\n")
        f.write("## ğŸ“ˆ ã‚¹ãƒ†ãƒ¼ã‚¸åˆ¥ç‰¹å¾´é‡ç¯„å›²\n\n")
        
        key_features = [
            'response_efficiency',
            'voltage_ratio',
            'waveform_correlation',
            'efficiency_degradation_rate'
        ]
        
        for stage in ['Normal', 'Degrading', 'Severe', 'Critical']:
            stage_data = df[df['degradation_stage'] == stage]
            if len(stage_data) == 0:
                continue
            
            f.write(f"### {stage} ã‚¹ãƒ†ãƒ¼ã‚¸\n\n")
            f.write(f"**ã‚µãƒ³ãƒ—ãƒ«æ•°**: {len(stage_data)}\n\n")
            f.write("| ç‰¹å¾´é‡ | å¹³å‡å€¤ | æ¨™æº–åå·® | æœ€å°å€¤ | æœ€å¤§å€¤ |\n")
            f.write("|--------|--------|----------|--------|--------|\n")
            
            for feat in key_features:
                if feat == 'efficiency_degradation_rate':
                    valid_data = stage_data[stage_data[feat].notna()]
                    if len(valid_data) == 0:
                        continue
                    mean_val = valid_data[feat].mean()
                    std_val = valid_data[feat].std()
                    min_val = valid_data[feat].min()
                    max_val = valid_data[feat].max()
                else:
                    mean_val = stage_data[feat].mean()
                    std_val = stage_data[feat].std()
                    min_val = stage_data[feat].min()
                    max_val = stage_data[feat].max()
                
                f.write(f"| {feat} | {mean_val:.2f} | {std_val:.2f} | {min_val:.2f} | {max_val:.2f} |\n")
            
            f.write("\n")
        
        f.write("---\n\n")
        f.write("## ğŸ¯ æ•…éšœå…†å€™æ¤œå‡ºã®æ¨å¥¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ\n\n")
        f.write("### æ—©æœŸè­¦å‘Šï¼ˆEarly Warningï¼‰\n")
        f.write("- **Response Efficiency < 50%**: åŠ£åŒ–é–‹å§‹ã®å…†å€™\n")
        f.write("- **Efficiency Degradation Rate > 0.5**: åˆæœŸåŠ¹ç‡ã‹ã‚‰50%ä»¥ä¸Šä½ä¸‹\n")
        f.write("- **Waveform Correlation > 0.95**: æ³¢å½¢å˜ç´”åŒ–ã®é–‹å§‹\n\n")
        
        f.write("### æ·±åˆ»ãªåŠ£åŒ–ï¼ˆSevere Degradationï¼‰\n")
        f.write("- **Response Efficiency < 10%**: æ·±åˆ»ãªå¿œç­”æ€§ä½ä¸‹\n")
        f.write("- **Efficiency Degradation Rate > 0.9**: åˆæœŸåŠ¹ç‡ã‹ã‚‰90%ä»¥ä¸Šä½ä¸‹\n")
        f.write("- **Waveform Correlation > 0.99**: æ·±åˆ»ãªæ³¢å½¢å˜ç´”åŒ–\n\n")
        
        f.write("### è‡¨ç•ŒçŠ¶æ…‹ï¼ˆCritical Stateï¼‰\n")
        f.write("- **Response Efficiency < 1%**: ã»ã¼å¿œç­”ãªã—\n")
        f.write("- **Efficiency Degradation Rate > 0.98**: åˆæœŸåŠ¹ç‡ã‹ã‚‰98%ä»¥ä¸Šä½ä¸‹\n")
        f.write("- **Waveform Correlation > 0.995**: å®Œå…¨ãªæ³¢å½¢å˜ç´”åŒ–\n\n")
        
        f.write("---\n\n")
        f.write("## ğŸ“ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«\n\n")
        f.write("1. `degradation_patterns_detailed.png` - åŠ£åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è©³ç´°å¯è¦–åŒ–\n")
        f.write("2. `degradation_stages_definition.md` - æœ¬ãƒ¬ãƒãƒ¼ãƒˆ\n\n")
        
        f.write("---\n\n")
        f.write("**å ±å‘Šè€…**: Kiro AI Agent  \n")
        f.write("**å®Œäº†æ—¥**: 2026-01-17  \n")
        f.write("**æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**: Phase 2 - ç•°å¸¸æ¤œçŸ¥ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰\n")
    
    print(f"âœ“ Saved: {report_path}")


def main():
    """Main execution."""
    print("="*80)
    print("DEGRADATION THRESHOLD ANALYSIS")
    print("="*80)
    
    # Load features
    print("\nLoading features...")
    df = pd.read_csv(FEATURES_PATH)
    print(f"  âœ“ Loaded {len(df)} samples")
    
    # Analyze threshold candidates
    threshold_results = analyze_threshold_candidates(df)
    
    # Define degradation stages
    df = define_degradation_stages(df)
    
    # Create visualizations
    visualize_degradation_patterns(df)
    
    # Create report
    create_threshold_analysis_report(df, threshold_results)
    
    print("\n" + "="*80)
    print("ANALYSIS COMPLETE!")
    print("="*80)
    print(f"\nOutput directory: {OUTPUT_DIR}")
    print("\nGenerated files:")
    print("  1. degradation_patterns_detailed.png")
    print("  2. degradation_stages_definition.md")
    print("\nâœ… Degradation threshold analysis complete!")


if __name__ == "__main__":
    main()
