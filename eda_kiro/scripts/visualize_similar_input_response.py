#!/usr/bin/env python3
"""
Visualize Response Changes for Similar Input Cycles

This script visualizes how output responses change over time for cycles with similar input patterns.
By plotting similar input cycles on the same scale, we can clearly see the degradation in response
characteristics while keeping the input patterns comparable.
"""

import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import h5py
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import warnings
from scipy.spatial.distance import pdist, squareform
from scipy.cluster.hierarchy import linkage, fcluster
from sklearn.metrics.pairwise import cosine_similarity
from scipy.stats import pearsonr

# Add project root to path
sys.path.append(str(Path(__file__).parent.parent / 'src'))

# Suppress warnings
warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=RuntimeWarning)

class SimilarInputResponseVisualizer:
    """Visualize response changes for similar input cycles"""
    
    def __init__(self, output_dir: Path = Path("output/similar_input_response")):
        self.output_dir = output_dir
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Set font to avoid rendering issues
        plt.rcParams['font.family'] = ['DejaVu Sans']
        
        # Color palette
        self.colors = plt.cm.viridis(np.linspace(0, 1, 10))
        
    def load_and_cluster_cycles(self, data_path: Path, capacitor_id: str, max_cycles: int = 50) -> Dict:
        """Load cycles and identify similar input clusters"""
        print(f"ğŸ“Š Loading and clustering cycles for {capacitor_id}...")
        
        with h5py.File(data_path, 'r') as f:
            cap_group = f['ES12']['Transient_Data'][capacitor_id]
            vl_data = cap_group['VL'][:]
            vo_data = cap_group['VO'][:]
            
            print(f"âœ… Raw data loaded: VL {vl_data.shape}, VO {vo_data.shape}")
            
            # Process cycles
            target_length = 3000
            cycles_data = {}
            valid_cycles = []
            vl_matrix = []
            
            for cycle_idx in range(min(max_cycles, vl_data.shape[1])):
                cycle_num = cycle_idx + 1
                
                vl_cycle = vl_data[:, cycle_idx]
                vo_cycle = vo_data[:, cycle_idx]
                
                # Remove NaN values
                valid_mask = ~np.isnan(vl_cycle) & ~np.isnan(vo_cycle)
                
                if np.sum(valid_mask) < target_length:
                    continue
                
                vl_clean = vl_cycle[valid_mask][:target_length]
                vo_clean = vo_cycle[valid_mask][:target_length]
                
                cycles_data[cycle_num] = {
                    'vl_raw': vl_clean,
                    'vo_raw': vo_clean,
                    'vl_mean': np.mean(vl_clean),
                    'vo_mean': np.mean(vo_clean),
                    'vl_std': np.std(vl_clean),
                    'vo_std': np.std(vo_clean),
                    'voltage_ratio': np.mean(vo_clean) / np.mean(vl_clean) if np.mean(vl_clean) != 0 else np.nan
                }
                
                vl_matrix.append(vl_clean)
                valid_cycles.append(cycle_num)
            
            print(f"âœ… Processed {len(valid_cycles)} valid cycles")
            
            # Calculate similarity and find clusters
            vl_matrix = np.array(vl_matrix)
            corr_matrix = np.corrcoef(vl_matrix)
            
            # Clustering
            distance_matrix = 1 - corr_matrix
            condensed_distances = squareform(distance_matrix, checks=False)
            linkage_matrix = linkage(condensed_distances, method='ward')
            cluster_labels = fcluster(linkage_matrix, 0.3, criterion='distance')
            
            # Group cycles by cluster
            clusters = {}
            for cycle_idx, cluster_id in enumerate(cluster_labels):
                cycle_num = valid_cycles[cycle_idx]
                if cluster_id not in clusters:
                    clusters[cluster_id] = []
                clusters[cluster_id].append(cycle_num)
            
            # Filter clusters with at least 3 cycles
            filtered_clusters = {cid: cycles for cid, cycles in clusters.items() if len(cycles) >= 3}
            
            print(f"ğŸ” Found {len(filtered_clusters)} clusters with similar inputs:")
            for cluster_id, cycle_list in filtered_clusters.items():
                print(f"   Cluster {cluster_id}: {len(cycle_list)} cycles {cycle_list}")
            
            return {
                'capacitor_id': capacitor_id,
                'cycles_data': cycles_data,
                'clusters': filtered_clusters,
                'valid_cycles': valid_cycles,
                'target_length': target_length
            }
    
    def visualize_similar_input_responses(self, cluster_data: Dict) -> Path:
        """Visualize response changes for similar input cycles on the same scale"""
        capacitor_id = cluster_data['capacitor_id']
        cycles_data = cluster_data['cycles_data']
        clusters = cluster_data['clusters']
        
        print(f"ğŸ“ˆ Creating similar input response visualization for {capacitor_id}...")
        
        # Create a comprehensive visualization
        n_clusters = len(clusters)
        fig, axes = plt.subplots(n_clusters, 3, figsize=(20, 6*n_clusters))
        if n_clusters == 1:
            axes = axes.reshape(1, -1)
        
        fig.suptitle(f'{capacitor_id} Response Changes for Similar Input Cycles', 
                     fontsize=16, fontweight='bold')
        
        cluster_colors = plt.cm.Set1(np.linspace(0, 1, n_clusters))
        
        for cluster_idx, (cluster_id, cycle_list) in enumerate(clusters.items()):
            sorted_cycles = sorted(cycle_list)
            
            print(f"   Processing Cluster {cluster_id} ({len(sorted_cycles)} cycles)...")
            
            # Find global scales for this cluster
            all_vl = np.concatenate([cycles_data[c]['vl_raw'] for c in sorted_cycles])
            all_vo = np.concatenate([cycles_data[c]['vo_raw'] for c in sorted_cycles])
            
            vl_global_min, vl_global_max = np.min(all_vl), np.max(all_vl)
            vo_global_min, vo_global_max = np.min(all_vo), np.max(all_vo)
            
            # Add some padding
            vl_padding = (vl_global_max - vl_global_min) * 0.05
            vo_padding = (vo_global_max - vo_global_min) * 0.05
            
            vl_ylim = [vl_global_min - vl_padding, vl_global_max + vl_padding]
            vo_ylim = [vo_global_min - vo_padding, vo_global_max + vo_padding]
            
            # 1. Input waveforms (VL) - Same scale
            ax1 = axes[cluster_idx, 0]
            
            cycle_colors = plt.cm.plasma(np.linspace(0, 1, len(sorted_cycles)))
            
            for i, cycle_num in enumerate(sorted_cycles):
                vl_data = cycles_data[cycle_num]['vl_raw']
                # Subsample for visualization
                subsample = max(1, len(vl_data) // 1000)
                time_points = np.arange(0, len(vl_data), subsample)
                vl_sub = vl_data[::subsample]
                
                ax1.plot(time_points, vl_sub, color=cycle_colors[i], alpha=0.7, linewidth=1.5,
                        label=f'Cycle {cycle_num}')
            
            ax1.set_title(f'Cluster {cluster_id}: Input Waveforms (VL)\nSimilar Input Patterns', 
                         fontweight='bold')
            ax1.set_xlabel('Time Points')
            ax1.set_ylabel('VL (Input Voltage)')
            ax1.set_ylim(vl_ylim)
            ax1.grid(True, alpha=0.3)
            ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            
            # 2. Output waveforms (VO) - Same scale
            ax2 = axes[cluster_idx, 1]
            
            for i, cycle_num in enumerate(sorted_cycles):
                vo_data = cycles_data[cycle_num]['vo_raw']
                # Subsample for visualization
                subsample = max(1, len(vo_data) // 1000)
                time_points = np.arange(0, len(vo_data), subsample)
                vo_sub = vo_data[::subsample]
                
                ax2.plot(time_points, vo_sub, color=cycle_colors[i], alpha=0.7, linewidth=1.5,
                        label=f'Cycle {cycle_num}')
            
            ax2.set_title(f'Cluster {cluster_id}: Output Responses (VO)\nResponse Changes Over Time', 
                         fontweight='bold')
            ax2.set_xlabel('Time Points')
            ax2.set_ylabel('VO (Output Voltage)')
            ax2.set_ylim(vo_ylim)
            ax2.grid(True, alpha=0.3)
            ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            
            # 3. Response characteristics comparison
            ax3 = axes[cluster_idx, 2]
            
            # Calculate response metrics for each cycle
            voltage_ratios = []
            correlations = []
            vo_amplitudes = []
            
            for cycle_num in sorted_cycles:
                cycle_data = cycles_data[cycle_num]
                voltage_ratios.append(cycle_data['voltage_ratio'])
                
                # Calculate correlation between VL and VO
                try:
                    correlation, _ = pearsonr(cycle_data['vl_raw'], cycle_data['vo_raw'])
                    correlations.append(correlation)
                except:
                    correlations.append(np.nan)
                
                # Calculate output amplitude (range)
                vo_amplitude = np.max(cycle_data['vo_raw']) - np.min(cycle_data['vo_raw'])
                vo_amplitudes.append(vo_amplitude)
            
            # Plot metrics
            x_pos = np.arange(len(sorted_cycles))
            
            # Normalize metrics for comparison
            if len(voltage_ratios) > 1:
                voltage_ratios_norm = np.array(voltage_ratios) / voltage_ratios[0]  # Relative to first cycle
            else:
                voltage_ratios_norm = np.array(voltage_ratios)
            
            if len(vo_amplitudes) > 1:
                vo_amplitudes_norm = np.array(vo_amplitudes) / vo_amplitudes[0]  # Relative to first cycle
            else:
                vo_amplitudes_norm = np.array(vo_amplitudes)
            
            ax3.plot(x_pos, voltage_ratios_norm, 'o-', color='red', linewidth=2, markersize=8,
                    label='Voltage Ratio (normalized)')
            ax3.plot(x_pos, correlations, 's-', color='blue', linewidth=2, markersize=8,
                    label='VL-VO Correlation')
            ax3.plot(x_pos, vo_amplitudes_norm, '^-', color='green', linewidth=2, markersize=8,
                    label='Output Amplitude (normalized)')
            
            ax3.set_title(f'Cluster {cluster_id}: Response Characteristics\nDegradation Metrics', 
                         fontweight='bold')
            ax3.set_xlabel('Cycle Index in Cluster')
            ax3.set_ylabel('Normalized Value')
            ax3.set_xticks(x_pos)
            ax3.set_xticklabels([f'C{c}' for c in sorted_cycles], rotation=45)
            ax3.legend()
            ax3.grid(True, alpha=0.3)
            ax3.axhline(1.0, color='black', linestyle='--', alpha=0.5, label='Reference')
            
            # Add degradation percentage text
            if len(voltage_ratios) > 1:
                degradation_pct = ((voltage_ratios[-1] - voltage_ratios[0]) / voltage_ratios[0]) * 100
                ax3.text(0.02, 0.98, f'Voltage Ratio Change: {degradation_pct:+.1f}%', 
                        transform=ax3.transAxes, verticalalignment='top',
                        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
        
        plt.tight_layout()
        
        plot_path = self.output_dir / f'{capacitor_id}_similar_input_response.png'
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        return plot_path
    
    def create_overlay_comparison(self, cluster_data: Dict) -> Path:
        """Create overlay comparison showing early vs late cycles for each cluster"""
        capacitor_id = cluster_data['capacitor_id']
        cycles_data = cluster_data['cycles_data']
        clusters = cluster_data['clusters']
        
        print(f"ğŸ“Š Creating overlay comparison for {capacitor_id}...")
        
        n_clusters = len(clusters)
        fig, axes = plt.subplots(n_clusters, 2, figsize=(16, 6*n_clusters))
        if n_clusters == 1:
            axes = axes.reshape(1, -1)
        
        fig.suptitle(f'{capacitor_id} Early vs Late Cycle Comparison - Similar Inputs', 
                     fontsize=16, fontweight='bold')
        
        for cluster_idx, (cluster_id, cycle_list) in enumerate(clusters.items()):
            sorted_cycles = sorted(cycle_list)
            
            # Select early and late cycles
            early_cycle = sorted_cycles[0]
            late_cycle = sorted_cycles[-1]
            
            early_data = cycles_data[early_cycle]
            late_data = cycles_data[late_cycle]
            
            # Find common scale
            all_vl = np.concatenate([early_data['vl_raw'], late_data['vl_raw']])
            all_vo = np.concatenate([early_data['vo_raw'], late_data['vo_raw']])
            
            vl_min, vl_max = np.min(all_vl), np.max(all_vl)
            vo_min, vo_max = np.min(all_vo), np.max(all_vo)
            
            # 1. Input comparison
            ax1 = axes[cluster_idx, 0]
            
            # Subsample for visualization
            subsample = max(1, len(early_data['vl_raw']) // 2000)
            time_points = np.arange(0, len(early_data['vl_raw']), subsample)
            
            early_vl = early_data['vl_raw'][::subsample]
            late_vl = late_data['vl_raw'][::subsample]
            
            ax1.plot(time_points, early_vl, color='blue', linewidth=2, alpha=0.8,
                    label=f'Early Cycle {early_cycle}')
            ax1.plot(time_points, late_vl, color='red', linewidth=2, alpha=0.8,
                    label=f'Late Cycle {late_cycle}')
            
            ax1.set_title(f'Cluster {cluster_id}: Input Comparison\nSimilar Input Patterns', 
                         fontweight='bold')
            ax1.set_xlabel('Time Points')
            ax1.set_ylabel('VL (Input Voltage)')
            ax1.set_ylim([vl_min - 0.01, vl_max + 0.01])
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            
            # Calculate input similarity
            input_correlation = np.corrcoef(early_data['vl_raw'], late_data['vl_raw'])[0, 1]
            ax1.text(0.02, 0.98, f'Input Correlation: {input_correlation:.3f}', 
                    transform=ax1.transAxes, verticalalignment='top',
                    bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))
            
            # 2. Output comparison
            ax2 = axes[cluster_idx, 1]
            
            early_vo = early_data['vo_raw'][::subsample]
            late_vo = late_data['vo_raw'][::subsample]
            
            ax2.plot(time_points, early_vo, color='blue', linewidth=2, alpha=0.8,
                    label=f'Early Response {early_cycle}')
            ax2.plot(time_points, late_vo, color='red', linewidth=2, alpha=0.8,
                    label=f'Late Response {late_cycle}')
            
            ax2.set_title(f'Cluster {cluster_id}: Response Comparison\nSame Input, Different Output', 
                         fontweight='bold')
            ax2.set_xlabel('Time Points')
            ax2.set_ylabel('VO (Output Voltage)')
            ax2.set_ylim([vo_min - 0.1, vo_max + 0.1])
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            
            # Calculate response changes
            early_ratio = early_data['voltage_ratio']
            late_ratio = late_data['voltage_ratio']
            ratio_change = ((late_ratio - early_ratio) / early_ratio) * 100 if early_ratio != 0 else np.nan
            
            early_amplitude = np.max(early_data['vo_raw']) - np.min(early_data['vo_raw'])
            late_amplitude = np.max(late_data['vo_raw']) - np.min(late_data['vo_raw'])
            amplitude_change = ((late_amplitude - early_amplitude) / early_amplitude) * 100 if early_amplitude != 0 else np.nan
            
            ax2.text(0.02, 0.98, f'Voltage Ratio Change: {ratio_change:+.1f}%\nAmplitude Change: {amplitude_change:+.1f}%', 
                    transform=ax2.transAxes, verticalalignment='top',
                    bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.8))
        
        plt.tight_layout()
        
        plot_path = self.output_dir / f'{capacitor_id}_overlay_comparison.png'
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        return plot_path
    
    def generate_response_report(self, cluster_data: Dict) -> Path:
        """Generate detailed response analysis report"""
        capacitor_id = cluster_data['capacitor_id']
        cycles_data = cluster_data['cycles_data']
        clusters = cluster_data['clusters']
        
        print(f"ğŸ“„ Generating response analysis report...")
        
        report_path = self.output_dir / f'{capacitor_id}_response_analysis_report.md'
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(f"# {capacitor_id} Similar Input Response Analysis Report\n\n")
            
            f.write("## Overview\n\n")
            f.write(f"Detailed analysis of response changes for cycles with similar input patterns.\n")
            f.write("By plotting similar input cycles on the same scale, we can clearly observe\n")
            f.write("how output responses degrade over time while input patterns remain similar.\n\n")
            
            f.write("## Analysis Approach\n\n")
            f.write("1. **Input Similarity Clustering**: Group cycles with similar VL patterns\n")
            f.write("2. **Same-Scale Visualization**: Plot similar inputs on identical scales\n")
            f.write("3. **Response Comparison**: Compare VO responses within each cluster\n")
            f.write("4. **Degradation Quantification**: Measure response changes over time\n\n")
            
            f.write("## Cluster Analysis Results\n\n")
            
            for cluster_id, cycle_list in clusters.items():
                sorted_cycles = sorted(cycle_list)
                
                f.write(f"### Cluster {cluster_id}\n\n")
                f.write(f"**Cycles**: {', '.join(map(str, sorted_cycles))}\n")
                f.write(f"**Time Span**: {sorted_cycles[-1] - sorted_cycles[0]} cycles\n")
                f.write(f"**Cluster Size**: {len(sorted_cycles)} cycles\n\n")
                
                # Calculate cluster statistics
                early_cycle = sorted_cycles[0]
                late_cycle = sorted_cycles[-1]
                
                early_data = cycles_data[early_cycle]
                late_data = cycles_data[late_cycle]
                
                # Input similarity
                input_correlation = np.corrcoef(early_data['vl_raw'], late_data['vl_raw'])[0, 1]
                
                # Response changes
                early_ratio = early_data['voltage_ratio']
                late_ratio = late_data['voltage_ratio']
                ratio_change = ((late_ratio - early_ratio) / early_ratio) * 100 if early_ratio != 0 else np.nan
                
                early_amplitude = np.max(early_data['vo_raw']) - np.min(early_data['vo_raw'])
                late_amplitude = np.max(late_data['vo_raw']) - np.min(late_data['vo_raw'])
                amplitude_change = ((late_amplitude - early_amplitude) / early_amplitude) * 100 if early_amplitude != 0 else np.nan
                
                f.write("#### Input Similarity\n")
                f.write(f"- **Early vs Late Input Correlation**: {input_correlation:.3f}\n")
                f.write(f"- **Input Pattern Consistency**: {'High' if input_correlation > 0.9 else 'Moderate' if input_correlation > 0.7 else 'Low'}\n\n")
                
                f.write("#### Response Changes\n")
                f.write(f"- **Voltage Ratio Change**: {ratio_change:+.1f}%\n" if not np.isnan(ratio_change) else "- **Voltage Ratio Change**: N/A\n")
                f.write(f"- **Output Amplitude Change**: {amplitude_change:+.1f}%\n" if not np.isnan(amplitude_change) else "- **Output Amplitude Change**: N/A\n")
                
                # Severity assessment
                if not np.isnan(ratio_change):
                    if abs(ratio_change) > 100:
                        f.write("- **Degradation Severity**: ğŸ”´ **Severe** (>100% change)\n")
                    elif abs(ratio_change) > 50:
                        f.write("- **Degradation Severity**: ğŸŸ¡ **Moderate** (50-100% change)\n")
                    elif abs(ratio_change) > 20:
                        f.write("- **Degradation Severity**: ğŸŸ  **Mild** (20-50% change)\n")
                    else:
                        f.write("- **Degradation Severity**: ğŸŸ¢ **Stable** (<20% change)\n")
                
                f.write("\n")
                
                # Detailed cycle-by-cycle analysis
                f.write("#### Cycle-by-Cycle Analysis\n\n")
                f.write("| Cycle | VL Mean | VO Mean | Voltage Ratio | Change from First |\n")
                f.write("|-------|---------|---------|---------------|-------------------|\n")
                
                first_ratio = cycles_data[sorted_cycles[0]]['voltage_ratio']
                
                for cycle_num in sorted_cycles:
                    cycle_data = cycles_data[cycle_num]
                    ratio = cycle_data['voltage_ratio']
                    change_pct = ((ratio - first_ratio) / first_ratio) * 100 if first_ratio != 0 else np.nan
                    
                    f.write(f"| {cycle_num} | {cycle_data['vl_mean']:.4f} | {cycle_data['vo_mean']:.4f} | ")
                    f.write(f"{ratio:.3f} | {change_pct:+.1f}% |\n" if not np.isnan(change_pct) else f"{ratio:.3f} | N/A |\n")
                
                f.write("\n")
            
            f.write("## Key Findings\n\n")
            
            # Overall analysis
            all_ratio_changes = []
            for cluster_id, cycle_list in clusters.items():
                sorted_cycles = sorted(cycle_list)
                if len(sorted_cycles) >= 2:
                    early_ratio = cycles_data[sorted_cycles[0]]['voltage_ratio']
                    late_ratio = cycles_data[sorted_cycles[-1]]['voltage_ratio']
                    ratio_change = ((late_ratio - early_ratio) / early_ratio) * 100 if early_ratio != 0 else np.nan
                    if not np.isnan(ratio_change):
                        all_ratio_changes.append(abs(ratio_change))
            
            if all_ratio_changes:
                avg_degradation = np.mean(all_ratio_changes)
                max_degradation = np.max(all_ratio_changes)
                
                f.write(f"1. **Average Degradation**: {avg_degradation:.1f}% voltage ratio change across clusters\n")
                f.write(f"2. **Maximum Degradation**: {max_degradation:.1f}% in worst-affected cluster\n")
            
            f.write(f"3. **Input Consistency**: Similar input patterns maintained across time\n")
            f.write(f"4. **Response Variability**: Clear degradation in output responses despite similar inputs\n")
            f.write(f"5. **Temporal Patterns**: Later cycles show progressively worse responses\n\n")
            
            f.write("## Visualization Benefits\n\n")
            f.write("- **Same-Scale Plotting**: Enables direct visual comparison of similar inputs\n")
            f.write("- **Response Isolation**: Clearly separates input consistency from output degradation\n")
            f.write("- **Temporal Tracking**: Shows progression of degradation over time\n")
            f.write("- **Quantitative Analysis**: Provides precise degradation measurements\n\n")
            
            f.write("## Conclusions\n\n")
            f.write("The same-scale visualization approach successfully demonstrates:\n\n")
            f.write("1. **Input Pattern Consistency**: VL patterns remain highly similar within clusters\n")
            f.write("2. **Output Response Degradation**: VO responses show clear degradation over time\n")
            f.write("3. **Measurable Changes**: Quantifiable degradation in voltage ratios and amplitudes\n")
            f.write("4. **Temporal Progression**: Systematic degradation pattern across operational cycles\n\n")
            
            f.write(f"---\n")
            f.write(f"Report Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        return report_path

def main():
    """Main execution function"""
    print("ğŸš€ Starting Similar Input Response Visualization")
    print("=" * 60)
    
    # Data path configuration
    data_path = Path("data/raw/ES12.mat")
    
    if not data_path.exists():
        print(f"âŒ Data file not found: {data_path}")
        return
    
    # Initialize visualizer
    visualizer = SimilarInputResponseVisualizer()
    
    try:
        # Configuration
        target_capacitor = "ES12C4"
        max_cycles = 50
        
        print(f"ğŸ¯ Analysis Target: {target_capacitor}")
        print(f"ğŸ”„ Max cycles to analyze: {max_cycles}")
        
        # Load and cluster cycles
        cluster_data = visualizer.load_and_cluster_cycles(data_path, target_capacitor, max_cycles)
        
        if not cluster_data['clusters']:
            print("âŒ No clusters found")
            return
        
        # Generate visualizations
        response_plot = visualizer.visualize_similar_input_responses(cluster_data)
        overlay_plot = visualizer.create_overlay_comparison(cluster_data)
        
        # Generate report
        report_path = visualizer.generate_response_report(cluster_data)
        
        # Summary
        print(f"\n" + "=" * 60)
        print("âœ… Similar Input Response Visualization Complete!")
        
        print(f"\nğŸ“Š Key Results:")
        clusters = cluster_data['clusters']
        for cluster_id, cycle_list in clusters.items():
            print(f"   Cluster {cluster_id}: {len(cycle_list)} cycles with similar inputs")
        
        print(f"\nğŸ“ Generated Files:")
        print(f"   - {response_plot.name}")
        print(f"   - {overlay_plot.name}")
        print(f"   - {report_path.name}")
        
        print(f"\nğŸ“ Output Directory: {visualizer.output_dir}")
        
        print(f"\nğŸ’¡ Visualization Benefits:")
        print(f"   - Same-scale plotting enables direct comparison")
        print(f"   - Clear separation of input consistency vs output degradation")
        print(f"   - Quantitative measurement of response changes")
        
    except Exception as e:
        print(f"âŒ Error occurred: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()